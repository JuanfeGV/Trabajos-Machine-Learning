{% extends "base.html" %}
{% block title %}Conceptos - Gradient Boosting Machines (GBM){% endblock %}
{% block content %}

<h1> MAPA CONCEPTUAL: Conceptos Basicos</h1>



<section>
    <h2>Conclusiones</h2>
<p>
  La clasificación en Machine Learning es un eje crucial para el análisis de datos porque posibilita la asignación de categorías basándose en patrones aprendidos en la información. 
</p>
<p>
  Hay diferentes perspectivas que difieren en términos de complejidad y aplicación: desde modelos lineales como las SVM y la regresión logística, hasta métodos fundamentados en distancia como k-NN, técnicas de probabilidades como Naive Bayes, y modelos más sofisticados como los ensambles o los árboles de decisión. 
</p>
<p>
  A la vez, las redes neuronales multicapa constituyen una opción eficaz para abordar problemas complejos y no lineales.
</p>

<p>
  No obstante, todos los algoritmos, más allá de las diferencias técnicas, requieren un preprocesamiento de datos apropiado y una evaluación rigurosa a través de métricas de desempeño. 
</p>
<p>
  Esto asegura, además de resultados exactos, interpretaciones fiables en el proceso de tomar decisiones. 
</p>
<p>
  En resumen, entender la clasificación no solo supone saber sobre los algoritmos, sino también identificar sus puntos fuertes y débiles y el contexto en el que son más apropiados.
</p>


<section>
    <h2>Bibliografía</h2>
    <ul>
        <li>Friedman, J. H. (2001). "Greedy Function Approximation: A Gradient Boosting Machine". <i>The Annals of Statistics</i>.</li>
        
        <li>Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow (Aurélien Géron, 2019).</li>
    </ul>
</section>

<div class="mt-4">
    <a href="{{ url_for('ejerciciosGBM') }}" class="btn btn-primary">Ir a ejercicios</a>
</div>

{% endblock %}
